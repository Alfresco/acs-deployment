os: linux
dist: xenial

git:
  depth: false

services:
  - docker

stages:
  - name: lint
  - name: test
  - name: community
  - name: 7.1.N
  - name: 7.0.N
  - name: 6.2.N
  - name: publish
    if: branch = master OR commit_message = "[publish]"

import:
  - source: Alfresco/alfresco-build-tools:.travis.awscli_install.yml@v1.3.0
  - source: Alfresco/alfresco-build-tools:.travis.aws-iam-authenticator_install.yml@v1.3.0
  - source: Alfresco/alfresco-build-tools:.travis.kubernetes_install.yml@v1.3.0
  - source: Alfresco/alfresco-build-tools:.travis.helm_install.yml@v1.3.0
  - source: Alfresco/alfresco-build-tools:.travis.kubepug_install.yml@v1.3.0
  - source: Alfresco/alfresco-build-tools:.travis.checkov_install.yml@v1.3.0
  - source: Alfresco/alfresco-build-tools:.travis.docker_hub_login.yml@v1.3.0
  - source: Alfresco/alfresco-build-tools:.travis.docker_login.yml@v1.3.0
  - source: Alfresco/alfresco-build-tools:.travis.helm-docs_install.yml@v1.3.0
  - source: Alfresco/alfresco-build-tools:.travis.yq_install.yml@v1.3.0
  - source: Alfresco/alfresco-build-tools:.travis.pre-commit.yml@v1.3.0

env:
  global:
    - TRAVIS_WAIT_TIMEOUT=${TRAVIS_WAIT_TIMEOUT:-30}
    - BRANCH=${TRAVIS_PULL_REQUEST_BRANCH:-${TRAVIS_BRANCH}}
    - GIT_DIFF=$(git diff origin/master --name-only .)

branches:
  only:
    - master
    - download-trial
    - /feature.*/
    - /fix.*/
    - /(?i:OPSEXP)-.*/
    - /ACS-.*/
    - /ATS-.*/

before_script:
  - |
    echo "GIT_DIFF=${GIT_DIFF}"
    echo "TRAVIS_COMMIT_MESSAGE=${TRAVIS_COMMIT_MESSAGE}"
    PROJECT_NAME=alfresco-content-services
    newman() {
      docker run -a STDOUT --volume $PWD/test/postman:/etc/newman --network host postman/newman:5.3 $*
    }

_helm_deploy: &helm_deploy
  script: |
    DOMAIN=dev.envalfresco.com
    SUFFIX=$(echo ${ACS_VERSION} | tr -d . | awk '{print tolower($0)}')
    namespace=$(echo ${TRAVIS_BRANCH} | cut -c1-28 | tr /_ - | tr -d '[:punct:]' | awk '{print tolower($0)}')-${TRAVIS_BUILD_NUMBER}-${SUFFIX}
    HOST=$namespace.${DOMAIN}
    release_name_ingress=ing-${TRAVIS_BUILD_NUMBER}-${SUFFIX}
    release_name_acs=acs-${TRAVIS_BUILD_NUMBER}-${SUFFIX}

    if [[ ${ACS_VERSION} != "latest" ]]; then
      values_file=helm/${PROJECT_NAME}/${ACS_VERSION}_values.yaml
    else
      values_file=helm/${PROJECT_NAME}/values.yaml
    fi

    if [[ "${TRAVIS_BRANCH}" == "master" ]] || \
       [[ "${TRAVIS_COMMIT_MESSAGE}" == *"[run all tests]"* ]] || \
       [[ "${TRAVIS_COMMIT_MESSAGE}" == *"[release]"* ]] || \
       [[ "${GIT_DIFF}" == *${values_file}* ]] || \
       [[ "${GIT_DIFF}" == *helm/${PROJECT_NAME}/templates* ]] || \
       [[ "${GIT_DIFF}" == *helm/${PROJECT_NAME}/charts* ]] || \
       [[ "${GIT_DIFF}" == *helm/${PROJECT_NAME}/requirements* ]] || \
       [[ "${GIT_DIFF}" == *test/postman/helm* ]]
    then
      echo deploying...
    else
      exit 0
    fi

    # Utility Functions

    pod_status() {
      kubectl get pods --namespace $namespace -o=custom-columns=NAME:.metadata.name,STATUS:.status.phase,READY:.status.conditions[?\(@.type==\'Ready\'\)].status
    }

    failed_pod_logs() {
      pod_status | grep False | awk '{print $1}' | while read pod; do echo -e '\e[1;31m' $pod '\e[0m' && kubectl logs $pod --namespace $namespace; done
    }

    pods_ready() {
      PODS_COUNTER=0
      PODS_COUNTER_MAX=60
      PODS_SLEEP_SECONDS=10

      while [ "$PODS_COUNTER" -lt "$PODS_COUNTER_MAX" ]; do
        totalpods=$(pod_status | grep -v NAME | wc -l | sed 's/ *//')
        readypodcount=$(pod_status | grep ' True' | wc -l | sed 's/ *//')
        if [ "$readypodcount" -eq "$totalpods" ]; then
              echo "     $readypodcount/$totalpods pods ready now"
              pod_status
          echo "All pods are ready!"
          break
        fi
          PODS_COUNTER=$((PODS_COUNTER + 1))
          echo "just $readypodcount/$totalpods pods ready now - sleeping $PODS_SLEEP_SECONDS seconds - counter $PODS_COUNTER"
          sleep "$PODS_SLEEP_SECONDS"
          continue
      done

      if [ "$PODS_COUNTER" -ge "$PODS_COUNTER_MAX" ]; then
        pod_status
        echo "Pods did not start - exit 1"
        failed_pod_logs
        if [[ "$TRAVIS_COMMIT_MESSAGE" != *"[keep env]"* ]]; then
          helm delete $release_name_ingress $release_name_acs -n $namespace
          kubectl delete namespace $namespace
        fi
        exit 1
      fi
    }

    # Main

    aws eks update-kubeconfig --name acs-cluster --region=eu-west-1

    cat <<EOF | kubectl apply -f -
    apiVersion: v1
    kind: Namespace
    metadata:
      name: $namespace
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: Role
    metadata:
      name: $namespace:psp
      namespace: $namespace
    rules:
    - apiGroups:
      - policy
      resourceNames:
      - kube-system
      resources:
      - podsecuritypolicies
      verbs:
      - use
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: RoleBinding
    metadata:
      name: $namespace:psp:default
      namespace: $namespace
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: Role
      name: $namespace:psp
    subjects:
    - kind: ServiceAccount
      name: default
      namespace: $namespace
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: RoleBinding
    metadata:
      name: $namespace:psp:$release_name_ingress-nginx-ingress
      namespace: $namespace
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: Role
      name: $namespace:psp
    subjects:
    - kind: ServiceAccount
      name: $release_name_ingress-nginx-ingress
      namespace: $namespace
    ---
    EOF

    kubectl create secret generic quay-registry-secret --from-file=.dockerconfigjson=/home/travis/.docker/config.json --type=kubernetes.io/dockerconfigjson -n $namespace

    # install ingress
    helm upgrade --install $release_name_ingress --repo https://kubernetes.github.io/ingress-nginx ingress-nginx --version=4.0.18 \
      --set controller.scope.enabled=true \
      --set controller.scope.namespace=$namespace \
      --set rbac.create=true \
      --set controller.config."proxy-body-size"="100m" \
      --set controller.service.targetPorts.https=80 \
      --set controller.service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-backend-protocol"="http" \
      --set controller.service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-ssl-ports"="https" \
      --set controller.service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-ssl-cert"="${ACM_CERTIFICATE}" \
      --set controller.service.annotations."external-dns\.alpha\.kubernetes\.io/hostname"="${HOST}" \
      --set controller.service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-ssl-negotiation-policy"="ELBSecurityPolicy-TLS-1-2-2017-01" \
      --set controller.service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-security-groups"="${AWS_SG}" \
      --set controller.publishService.enabled=true \
      --set controller.admissionWebhooks.enabled=false \
      --set controller.ingressClassResource.enabled=false \
      --wait \
      --namespace $namespace

    # install acs
    helm dep up helm/${PROJECT_NAME}
    travis_wait 25 helm upgrade --install $release_name_acs helm/${PROJECT_NAME} \
      --values=$values_file \
      --set global.tracking.sharedsecret=$(openssl rand 24 -hex) \
      --set externalPort="443" \
      --set externalProtocol="https" \
      --set externalHost="${HOST}" \
      --set persistence.enabled=true \
      --set persistence.storageClass.enabled=true \
      --set persistence.storageClass.name="nfs-client" \
      --set postgresql.persistence.existingClaim="" \
      --set postgresql-syncservice.persistence.existingClaim="" \
      --set global.alfrescoRegistryPullSecrets=quay-registry-secret \
      --wait \
      --timeout 20m0s \
      --namespace=$namespace

    # check dns and pods
    DNS_PROPAGATED=0
    DNS_COUNTER=0
    DNS_COUNTER_MAX=90
    DNS_SLEEP_SECONDS=10

    echo "Trying to perform a trace DNS query to prevent caching"
    dig +trace ${HOST} @8.8.8.8
    while [ "$DNS_PROPAGATED" -eq 0 ] && [ "$DNS_COUNTER" -le "$DNS_COUNTER_MAX" ]; do
      host ${HOST} 8.8.8.8
      if [ "$?" -eq 1 ]; then
        DNS_COUNTER=$((DNS_COUNTER + 1))
        echo "DNS Not Propagated - Sleeping $DNS_SLEEP_SECONDS seconds"
        sleep "$DNS_SLEEP_SECONDS"
      else
        echo "DNS Propagated"
        DNS_PROPAGATED=1
      fi
    done

    [ $DNS_PROPAGATED -ne 1 ] && echo "DNS entry for ${HOST} did not propagate within expected time" && exit 1

    pods_ready

    # Delay running the tests to give ingress & SOLR a chance to fully initialise
    echo "Waiting 3 minutes from $(date) before running tests..."
    sleep 180

    # run acs checks
    newman run helm/acs-test-helm-collection.json --global-var "protocol=https" --global-var "url=${HOST}"
    TEST_RESULT=$?
    echo "TEST_RESULT=${TEST_RESULT}"
    if [[ "${TEST_RESULT}" == "0" ]]; then
      # run sync service checks
      if [[ ${ACS_VERSION} != "community" ]]; then
        newman run "helm/sync-service-test-helm-collection.json" --global-var "protocol=https" --global-var "url=${HOST}"
        TEST_RESULT=$?
        echo "TEST_RESULT=${TEST_RESULT}"
      fi

      if [[ "${TEST_RESULT}" == "0" ]]; then
        # For checking if persistence failover is correctly working with our deployments
        # in the next phase we delete the acs and postgresql pods,
        # wait for k8s to recreate them, then check if the data created in the first test run is still there
        kubectl delete pod -l app=$release_name_acs-alfresco-cs-repository,component=repository -n $namespace
        kubectl delete pod -l app=postgresql-acs,release=$release_name_acs -n $namespace
        helm upgrade $release_name_acs helm/${PROJECT_NAME} \
          --wait \
          --timeout 10m0s \
          --reuse-values \
          --namespace=$namespace

        # check pods
        pods_ready

        # run checks after pod deletion
        newman run "helm/acs-validate-volume-collection.json" --global-var "protocol=https" --global-var "url=${HOST}"
        TEST_RESULT=$?
        echo "TEST_RESULT=${TEST_RESULT}"
      fi
    fi

    if [[ "$TRAVIS_COMMIT_MESSAGE" != *"[keep env]"* ]]; then
      helm delete $release_name_ingress $release_name_acs -n $namespace
      kubectl delete namespace $namespace
    fi

    if [[ "${TEST_RESULT}" == "1" ]]; then
      echo "Tests failed, exiting"
      exit 1
    fi

_docker_deploy: &docker_deploy
  script: |
    alf_port=8080
    if [[ ${ACS_VERSION} == "latest" ]]
    then
      compose_file="docker-compose.yml"
    else
      compose_file="${ACS_VERSION}-docker-compose.yml"
    fi

    if [[ "${TRAVIS_BRANCH}" == "master" ]] || \
       [[ "${TRAVIS_COMMIT_MESSAGE}" == *"[run all tests]"* ]] || \
       [[ "${TRAVIS_COMMIT_MESSAGE}" == *"[release]"* ]] || \
       [[ "${GIT_DIFF}" == *$compose_file* ]] || \
       [[ "${GIT_DIFF}" == *test/postman/docker-compose* ]]
    then
      echo deploying...
    else
      exit 0
    fi

    # deploy
    cd docker-compose
    docker info
    docker-compose --version
    docker-compose -f $compose_file config
    echo "Starting Alfresco in Docker Compose"
    docker-compose ps
    docker-compose -f $compose_file pull
    export COMPOSE_HTTP_TIMEOUT=120
    docker-compose -f $compose_file up -d
    cd ..

    # test with curl
    WAIT_INTERVAL=1
    COUNTER=0
    TIMEOUT=300
    t0=`date +%s`
    echo "Waiting for alfresco to start"
    response=$(curl --write-out %{http_code} --output /dev/null --silent http://localhost:$alf_port/alfresco/)
    until [[ "200" -eq "$response" ]] || [[ "$COUNTER" -eq "$TIMEOUT" ]]; do
      printf '.'
      sleep $WAIT_INTERVAL
      COUNTER=$((COUNTER + WAIT_INTERVAL))
      response=$(curl --write-out %{http_code} --output /dev/null --silent http://localhost:$alf_port/alfresco/)
    done
    if (("$COUNTER" < "$TIMEOUT")) ; then
      t1=`date +%s`
      delta=$(((t1 - t0)/60))
      echo "Alfresco Started in $delta minutes"
    else
      echo "Waited $COUNTER seconds"
      echo "Alfresco could not start in time."
      echo "The last response code from /alfresco/ was $response"
      exit 1
    fi
    COUNTER=0
    echo "Waiting for share to start"
    response=$(curl --write-out %{http_code} --output /dev/null --silent http://localhost:8080/share/page)
    until [[ "200" -eq "$response" ]] || [[ "$COUNTER" -eq "$TIMEOUT" ]]; do
      printf '.'
      sleep $WAIT_INTERVAL
      COUNTER=$((COUNTER + WAIT_INTERVAL))
      response=$(curl --write-out %{http_code} --output /dev/null --silent http://localhost:8080/share/page)
    done
    if (("$COUNTER" < "$TIMEOUT")) ; then
      t1=`date +%s`
      delta=$(((t1 - t0)/60))
      echo "Share Started in $delta minutes"
    else
      echo "Waited $COUNTER seconds"
      echo "Share could not start in time."
      echo "The last response code from /share/ was $response"
      exit 1
    fi
    COUNTER=0
    TIMEOUT=20
    echo "Waiting more time for SOLR"
    response=$(curl --write-out %{http_code} --user admin:admin --output /dev/null --silent http://localhost:$alf_port/alfresco/s/api/solrstats)
    until [[ "200" -eq "$response" ]] || [[ "$COUNTER" -eq "$TIMEOUT" ]]; do
      printf '.'
      sleep $WAIT_INTERVAL
      COUNTER=$((COUNTER + WAIT_INTERVAL))
      response=$(curl --write-out %{http_code} --user admin:admin --output /dev/null --silent http://localhost:$alf_port/alfresco/s/api/solrstats)
    done

    # test with newman
    newman run "docker-compose/acs-test-docker-compose-collection.json" --global-var "protocol=http" --global-var "url=localhost:8080"
  after_success: |
    echo "nothing to cleanup"
  after_failure: |
    cd docker-compose
    docker-compose logs --no-color

jobs:
  include:

    - name: latest-helm
      stage: test
      env: ACS_VERSION=latest
      <<: *helm_deploy
    - name: latest-docker-compose
      stage: test
      env: ACS_VERSION=latest
      <<: *docker_deploy

    - name: community-helm
      stage: community
      env: ACS_VERSION=community
      <<: *helm_deploy
    - name: community-docker-compose
      stage: community
      env: ACS_VERSION=community
      <<: *docker_deploy

    - name: 7.1.N-helm
      stage: 7.1.N
      env: ACS_VERSION=7.1.N
      <<: *helm_deploy
    - name: 7.1.N-docker-compose
      stage: 7.1.N
      env: ACS_VERSION=7.1.N
      <<: *docker_deploy

    - name: 7.0.N-helm
      stage: 7.0.N
      env: ACS_VERSION=7.0.N
      <<: *helm_deploy
    - name: 7.0.N-docker-compose
      stage: 7.0.N
      env: ACS_VERSION=7.0.N
      <<: *docker_deploy

    - name: 6.2.N-helm
      stage: 6.2.N
      env: ACS_VERSION=6.2.N
      <<: *helm_deploy
    - name: 6.2.N-docker-compose
      stage: 6.2.N
      env: ACS_VERSION=6.2.N
      <<: *docker_deploy

    - name: package and publish chart
      stage: publish
      script: |
        HELM_REPO_BASE_URL=https://kubernetes-charts.alfresco.com
        HELM_REPO=incubator
        CHART_VERSION=$(yq eval .version helm/${PROJECT_NAME}/Chart.yaml)
        ALPHA_BUILD_VERSION="${CHART_VERSION%-*}-A${TRAVIS_BUILD_NUMBER}"
        if [[ "${TRAVIS_BRANCH}" != "master" ]]; then
          echo "Changing Chart version to ${ALPHA_BUILD_VERSION} as this is a feature branch..."
          sed -i s,$CHART_VERSION,$ALPHA_BUILD_VERSION,g helm/${PROJECT_NAME}/Chart.yaml
        elif [[ "${TRAVIS_COMMIT_MESSAGE}" == *"[release]"* ]]; then
          export HELM_REPO=stable
          git checkout -B "${TRAVIS_BRANCH}"
          git config --local user.email "alfresco-build@alfresco.com"
          echo "Tagging repository with v$CHART_VERSION..."
          export GIT_TAG="v$CHART_VERSION"
          git tag $GIT_TAG -a -m "Generated tag from TravisCI for build $TRAVIS_BUILD_NUMBER"
          git push https://$GITHUB_TOKEN@github.com/Alfresco/acs-deployment $GIT_TAG
          git tag -d latest || true
          git tag -a -m "current latest -> $GIT_TAG" -f latest ${GIT_TAG}^{}
          for ref in ':refs/tags/latest' 'latest'
            do git push https://$GITHUB_TOKEN@github.com/Alfresco/acs-deployment $ref
          done
        fi

        COMMIT_MESSAGE_FIRST_LINE=$(git log --pretty=format:%s --max-count=1)
        echo using COMMIT_MESSAGE_FIRST_LINE=${COMMIT_MESSAGE_FIRST_LINE}
        git clone https://${GITHUB_TOKEN}@github.com/Alfresco/charts.git
        echo using PROJECT_NAME=${PROJECT_NAME},BRANCH=${BRANCH},HELM_REPO=${HELM_REPO}
        mkdir repo
        helm package --dependency-update --destination repo helm/${PROJECT_NAME}
        helm repo index repo --url ${HELM_REPO_BASE_URL}/${HELM_REPO} --merge charts/${HELM_REPO}/index.yaml
        mv repo/* charts/${HELM_REPO}
        cd charts
        git add ${HELM_REPO}
        git commit -m "${COMMIT_MESSAGE_FIRST_LINE}"
        git push --quiet origin master
